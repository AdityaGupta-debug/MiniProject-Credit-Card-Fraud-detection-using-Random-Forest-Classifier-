# ğŸ’³ Credit Card Fraud Detection Dataset

## ğŸ“Œ About the Dataset

This project uses a real-world dataset consisting of **credit card transactions made by European cardholders in September 2013**.  
It contains **284,807 transactions over two days**, of which only **492 are fraudulent** â€” making this a **highly imbalanced classification problem** (~0.17% fraud rate).

Due to confidentiality, most features have been anonymized using **Principal Component Analysis (PCA)**.  
Only `Time` and `Amount` retain their original values.

The target column is `Class`, where:
- `0` â†’ Legitimate transaction  
- `1` â†’ Fraudulent transaction

---

## ğŸ§© Features

- `Time`: Time in seconds since the first transaction  
- `V1` to `V28`: Principal components obtained via PCA  
- `Amount`: Transaction amount in Euros  
- `Class`: Target variable (0 = Non-fraud, 1 = Fraud)

---

## âš™ï¸ Algorithms Used

I experimented with multiple machine learning models to classify transactions as fraudulent or legitimate:

- ğŸ“ˆ Logistic Regression  
- ğŸ”µ Support Vector Classifier (SVC)  
- ğŸŒ² Decision Tree Classifier  
- ğŸ“ K-Nearest Neighbors (KNN)  
- ğŸŒ³ Random Forest Classifier âœ…

Out of all, **Random Forest** performed the best in terms of:
- **Precision**
- **Recall**
- **Overall accuracy**

Its **ensemble structure** made it robust to noise and well-suited for handling the **class imbalance**.

---

## ğŸ“ˆ Challenges & Techniques Used

### âš ï¸ Class Imbalance
- Applied **resampling techniques** (e.g., undersampling)  
- Focused on **Recall**, **Precision**, and **F1-score** over plain Accuracy  
- Used **ROC-AUC** to assess model discrimination

### ğŸ“Š Feature Scaling
- Scaled `Time` and `Amount` for models sensitive to feature magnitude (e.g., Logistic Regression, SVC)

### âœ… Model Evaluation
- Accuracy was not the primary metric due to imbalance  
- **False negatives** were minimized as detecting fraud is more critical than false alarms

---

## ğŸ“š Conclusion

The **Random Forest Classifier** delivered the **most reliable and balanced performance**, making it the best model for this fraud detection task.  
To further enhance detection:

- Consider **Balanced Random Forests**  
- Apply **SMOTE** or **ADASYN** for synthetic oversampling  
- Explore **anomaly detection methods** like Isolation Forest or Autoencoders

This project emphasizes the importance of **careful metric selection and model tuning** when working with imbalanced datasets in high-stakes domains like fraud detection.
